# HW07 – Report

> Файл: `homeworks/HW07/report.md`  
> Важно: не меняйте названия разделов (заголовков). Заполняйте текстом и/или вставляйте результаты.

## 1. Datasets

Вы выбрали 3 датасета из 4: Dataset 1, Dataset 2, Dataset 3.

### 1.1 Dataset A

- Файл: `S07-hw-dataset-01.csv`
- Размер: (количество строк, количество столбцов) – 12000 x 9
- Признаки: числовые
- Пропуски: нет
- "Подлости" датасета: признаки в разных шкалах, есть шумовые признаки

### 1.2 Dataset B

- Файл: `S07-hw-dataset-02.csv`
- Размер: 8000 x 4
- Признаки: числовые
- Пропуски: нет
- "Подлости" датасета: нелинейная структура, выбросы, шум

### 1.3 Dataset C

- Файл: `S07-hw-dataset-03.csv`
- Размер: 15000 x 5
- Признаки: числовые
- Пропуски: нет
- "Подлости" датасета: кластеры разной плотности, фоновый шум

## 2. Protocol

Опишите ваш "честный" unsupervised-протокол.

- **Препроцессинг:**  
  - Масштабирование числовых признаков: `StandardScaler`  
  - Пропусков нет → `SimpleImputer` не применялся  
  - Категориальных признаков нет  
  - Применялся `Pipeline` с `ColumnTransformer` для единообразия  

- **Поиск гиперпараметров:**  
  - KMeans: k от 2 до 20, фиксировали `random_state` и `n_init`  
  - DBSCAN: подбор eps через kNN plot (локоть на графике), `min_samples=5`  
  - Выбор "лучшего" метода ориентировался на сочетание метрик Silhouette, Calinski-Harabasz, Davies-Bouldin и на визуальное разделение кластеров  

- **Метрики:**  
  - Silhouette Score  
  - Davies-Bouldin Score  
  - Calinski-Harabasz Score  
  - Для DBSCAN считали метрики только на non-noise точках, отдельно фиксировали долю шума  

- **Визуализация:**  
  - PCA 2D scatter для наглядного отображения кластеров  
  - Silhouette vs k и kNN plot для подбора eps

## 3. Models

- Для каждого датасета сравнивались минимум 2 алгоритма:  

**Dataset 1:**  
- KMeans (`k=2..20`, `random_state`, `n_init`)  
- DBSCAN (`eps`, `min_samples=5`)  

**Dataset 2:**  
- KMeans (`k=2..20`)  
- DBSCAN (`eps`, `min_samples=6`)  

**Dataset 3:**  
- KMeans (`k=2..20`)  
- DBSCAN (`eps`, `min_samples=12`)  

Параметры подбирались по метрикам Silhouette и визуальной оценке кластеров.

## 4. Results

### 4.1 Dataset A

- **Лучший метод и параметры:** KMeans, k=2, random_state=42, n_init=10  
- **Метрики:**  
  - Silhouette: 0.522  
  - Davies-Bouldin: 0.685  
  - Calinski-Harabasz: 11786.955  
- **DBSCAN:** eps=0.7, min_samples=5, доля шума 0.004, Silhouette 0.380  
- **Комментарий:** Чёткая структура кластеров, KMeans стабильный (ARI=1), DBSCAN хуже по метрикам, выбор KMeans оправдан линейной структурой и одинаковой плотностью кластеров  

### 4.2 Dataset B

- **Лучший метод и параметры:** DBSCAN, eps=0.28,  min_samples=6 
- **Метрики:**  
  - Silhouette Score (non-noise): 0.271
  - Davies-Bouldin Score (non-noise): 0.653
  - Calinski-Harabasz Score (non-noise): 15.718
- **KMeans:** k=2, random_state=42, n_init=10 
- **Комментарий:** Нелинейная структура и выбросы мешают KMeans и заставляют находить ложные кластеры  

### 4.3 Dataset C

- **Лучший метод и параметры:** KMeans, k=3, random_state=42, n_init=10  
- **Метрики:**  
  - Silhouette: 0.316  
  - Davies-Bouldin: 1.158  
  - Calinski-Harabasz: 6957.163  
- **DBSCAN:** eps=0.45, min_samples=5, доля шума 0.032, Silhouette 0.055  
- **Комментарий:** Кластеры разной плотности, DBSCAN плохо справляется, KMeans даёт более интерпретируемое и стабильное разбиение

## 5. Analysis

### 5.1 Сравнение алгоритмов (важные наблюдения)

- KMeans "ломается", когда кластеры сильно нелинейны или имеют разную плотность → метрики падают.  
- DBSCAN выигрывает на датасетах с плотными кластерами и шумовыми точками, но чувствителен к eps.  
- На результат сильно влияют: масштабирование признаков, наличие выбросов и плотность кластеров. Пропуски отсутствуют, категориальных признаков нет.

### 5.2 Устойчивость (обязательно для одного датасета)

- Проверка: KMeans Dataset 1, 5 запусков с разными random_state  
- Результат: ARI между всеми запусками = 1.0  
- Вывод: разбиение абсолютно устойчиво, структура кластеров чёткая и стабильная, алгоритм не зависит от инициализации

### 5.3 Интерпретация кластеров

- Кластеры выделены по схожести признаков (средние значения по числовым столбцам)  
- Dataset 1: два чётких кластера  
- Dataset 2: Один кластер с шумом
- Dataset 3: три кластера сильно сливаются 
- Вывод: KMeans даёт интерпретируемое разбиение, DBSCAN в сложных структурах уступает

## 6. Conclusion

- Масштабирование признаков критично для корректной работы KMeans и DBSCAN  
- Наличие выбросов ухудшает эффективность DBSCAN  
- KMeans стабилен при равномерной плотности кластеров  
- DBSCAN полезен для выявления шума и плотных кластеров  
- Метрики Silhouette, Davies-Bouldin и Calinski-Harabasz дают разную перспективу на качество кластеров  
- Устойчивость алгоритмов проверять обязательно, хотя бы на одном датасете  
- PCA 2D scatter помогает визуально оценить качество кластеризации  
- Для сложных датасетов с нелинейными структурами DBSCAN может требовать тщательного подбора eps
